{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, LSTM, Dropout, TimeDistributed, Lambda, Flatten, GlobalAveragePooling1D\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "#import random\n",
    "import math\n",
    "#import tf.contrib.distributions.NormalWithSoftplusScale as NORM\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import theano\n",
    "\n",
    "def plot(label,prediction,vi, num_plot,k,e): # 1,192  1,192  1,192\n",
    "    x = np.arange(192)\n",
    "    f = plt.figure()\n",
    "    base = num_plot*100+10\n",
    "    for i in range(num_plot):\n",
    "        label_temp = label[i].reshape([window_length,]) * vi[i]\n",
    "        pred_temp = prediction[i].reshape([window_length,]) * vi[i]\n",
    "        plt.subplot(base+i+1)\n",
    "        plt.plot(x,label_temp, color='b')\n",
    "        plt.plot(x,pred_temp, color='r')        \n",
    "        plt.axvline(168, color='k')\n",
    "    #plt.pause(5)\n",
    "#    plot.show()\n",
    "    print('saving...')\n",
    "    f.savefig(str(e)+'thEpoch'+str(k)+\"thBatch.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def log_gaussian(x, mean, std):\n",
    "    #dist = tf.contrib.distributions.NormalWithSoftplusScale(mean,std)\n",
    "    dist = tf.contrib.distributions.Normal(mean,std)\n",
    "    likelihood = dist.log_prob(x)\n",
    "    return likelihood\n",
    "\n",
    "def sum_log_likelihood(y_true, para_pred):\n",
    "    print('\\n==in custom loss===')\n",
    "    print(\"y_true.shape: \", y_true.shape)\n",
    "    print(\"para_pred.shape: \", para_pred.shape)\n",
    "    mean = para_pred[:,:,0]\n",
    "    std = (para_pred[:,:,1])\n",
    "    print(\"mean.shape: \", mean.shape)\n",
    "    print('std.shape: ', std.shape)\n",
    "    likelihood = log_gaussian(y_true[:,:,0], mean, std)\n",
    "    print(\"likelihood.shape: \",likelihood.shape)\n",
    "    print('==end of custom loss===')\n",
    "    result =  K.mean(likelihood)\n",
    "    return -result\n",
    "\n",
    "\n",
    "data = np.load('reframed-data-all.npy')\n",
    "#data = data[0:1000, :, :]\n",
    "v_i = np.load('vi-g-all.npy')\n",
    "#v_i = v_i[0:1000, :]\n",
    "print(\"data.shape: \", data.shape)\n",
    "print(\"v_i.shape: \", v_i.shape)\n",
    "\n",
    "\n",
    "# get the dimension\n",
    "input_window_length = 168\n",
    "output_window_length = 24\n",
    "window_length = input_window_length + output_window_length\n",
    "n_features = 4\n",
    "n_dims = 370\n",
    "input_embed_dim = 370\n",
    "output_embed_dim = 20\n",
    "n_samples = data.shape[0]\n",
    "N = ((int(n_samples * 0.95)) // 64) * 64 # number of samples in train data\n",
    "\n",
    "aux_in = Input(shape=(None, ), name='aux_input', dtype='int32')\n",
    "\n",
    "aux_in_full = Lambda(K.one_hot, arguments={'num_classes': n_dims}, output_shape=(None, n_dims))(aux_in)\n",
    "x = Dense(20, activation='sigmoid')(aux_in_full)\n",
    "\n",
    "main_in = Input(shape=(None, n_features, ), name=\"main_input\")\n",
    "input1 = layers.concatenate([main_in, x])\n",
    "\n",
    "lstm_out1 = LSTM(40, return_sequences = True)(input1)\n",
    "drop_out1 = Dropout(0.2)(lstm_out1)\n",
    "lstm_out2 = LSTM(40,  return_sequences = True)(drop_out1)\n",
    "drop_out2 = Dropout(0.2)(lstm_out2)\n",
    "lstm_out3 = LSTM(40,  return_sequences = True)(lstm_out2)\n",
    "drop_out3 = Dropout(0.2)(lstm_out3)\n",
    "\n",
    "\n",
    "mean_for_each = TimeDistributed(Dense(1))(drop_out3)\n",
    "std_for_each = TimeDistributed(Dense(1, activation='softplus'))(lstm_out3)\n",
    "out_for_each = layers.concatenate([mean_for_each,std_for_each],axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[aux_in,main_in], outputs=[mean_for_each, std_for_each])\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "model.compile(loss=\"mean_squared_logarithmic_error\", optimizer=adam)\n",
    "#model.compile(loss=sum_log_likelihood, optimizer=adam)\n",
    "print(model.summary())\n",
    "\n",
    "train_main_input = data[:N,:, 0:4] # ground truth and covariates\n",
    "train_aux_input =  np.array(data[:N,:,4], dtype='int32') # the one-hot position\n",
    "#train_aux_input = (np.arange(n_dims) == train_aux_input[...,None]-1).astype(np.int32, copy=False)\n",
    "train_y = data[:N,:,5].reshape(-1, window_length, 1)\n",
    "\n",
    "print(train_main_input.shape, train_aux_input.shape)\n",
    "\n",
    "\n",
    "train_y.shape\n",
    "\n",
    "test_main_input = data[N:,:,0:4] # ground truth and covariates\n",
    "test_aux_input = np.array(data[N:,:,4], dtype='int32') # the one-hot position\n",
    "test_vi = v_i[N:, :]\n",
    "rewritten_input = np.copy(test_main_input)\n",
    "batch_size = 32\n",
    "n_batch = (n_samples - N) // batch_size\n",
    "\n",
    "nd = np.zeros(n_batch)\n",
    "rmse = np.zeros(n_batch)\n",
    "\n",
    "n_epoches = 1\n",
    "\n",
    "\n",
    "def rmse_metrics(y_true, mean, vi):\n",
    "    y_true = y_true * vi\n",
    "    mean = mean * vi\n",
    "    denom = np.mean(np.absolute(y_true))\n",
    "    if (denom == 0.0):\n",
    "        denom = -1.0\n",
    "    return math.sqrt(np.mean(np.square(mean-y_true)))/denom\n",
    "\n",
    "def nd_metrics(y_true, mean, vi):\n",
    "    y_true = y_true * vi\n",
    "    mean = mean * vi\n",
    "    denom = np.sum(np.absolute(y_true))\n",
    "    if (denom == 0.0):\n",
    "        denom = -1.0\n",
    "    return np.sum(np.absolute(mean-y_true))/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('epoch: ', 1, '/', 1)\n",
      "Epoch 1/1\n",
      "412480/412480 [==============================] - 7960s 19ms/step - loss: 0.0034\n",
      "saving...\n",
      "(0.06406789346662124, 0.19568581893089138)\n",
      "saving...\n",
      "(0.0824951705952719, 0.18316715325884653)\n",
      "saving...\n",
      "(0.08342865966546677, 0.21778168534949657)\n",
      "saving...\n",
      "(0.06932534503023759, 0.3541152743677562)\n",
      "saving...\n",
      "(0.07495595686479152, 0.45123543186677034)\n",
      "saving...\n",
      "(0.06160737065784354, 0.10913310211896918)\n",
      "saving...\n",
      "(0.07278088990696054, 0.1431974689251798)\n",
      "saving...\n",
      "(0.09479884178444298, 0.22656972947746362)\n",
      "saving...\n",
      "(0.06788978636510778, 0.15024976413355762)\n",
      "saving...\n",
      "(0.056289661469732195, 0.30056702045673866)\n",
      "saving...\n",
      "(0.06227650998758103, 0.22041027265573288)\n",
      "saving...\n",
      "(0.05392237447492655, 0.1805338585182529)\n",
      "saving...\n",
      "(0.08834967889838229, 0.22266016650218978)\n",
      "saving...\n",
      "(0.08758844711215365, 0.22209681214588844)\n",
      "saving...\n",
      "(0.08622071219627975, 0.2008304749283855)\n",
      "saving...\n",
      "(0.04361565155526009, 0.16569935132881428)\n",
      "saving...\n",
      "(0.04315775903466117, 0.14683582130319842)\n",
      "saving...\n",
      "(0.0724374810606736, 0.2639607901112819)\n",
      "saving...\n",
      "(0.081497844898128, 0.21056014830147685)\n",
      "saving...\n",
      "(0.08328856802392393, 0.2850912148364369)\n",
      "saving...\n",
      "(0.0752225344728266, 0.23165559338137726)\n",
      "saving...\n",
      "(0.05620237785438487, 0.1366831858061987)\n",
      "saving...\n",
      "(0.07594568007725877, 0.19946350639843044)\n",
      "saving...\n",
      "(0.12031042442045918, 0.3558399898729515)\n",
      "saving...\n",
      "(0.07931594622845033, 0.1670121819730006)\n",
      "saving...\n",
      "(0.1260413439054712, 0.3320654591748122)\n",
      "saving...\n",
      "(0.07741777036014881, 0.19890112754198594)\n",
      "saving...\n",
      "(0.0965882983426082, 0.20713420825390438)\n",
      "saving...\n",
      "(0.08527877047381355, 0.20433230038857056)\n",
      "saving...\n",
      "(0.10476777075793024, 0.27489675634737915)\n",
      "saving...\n",
      "(0.08374316229236771, 0.15217562580372432)\n",
      "saving...\n",
      "(0.09385840739583365, 0.23683808159800168)\n",
      "saving...\n",
      "(0.08867399607042482, 0.4443258200531852)\n",
      "saving...\n",
      "(0.0733508779234449, 0.2865371264614669)\n",
      "saving...\n",
      "(0.09551976945762075, 0.4597848744079653)\n",
      "saving...\n",
      "(0.05150056704341285, 0.1420315963200357)\n",
      "saving...\n",
      "(0.09133999518798755, 0.23680454661314518)\n",
      "saving...\n",
      "(0.05422256125971026, 0.16836912222569514)\n",
      "saving...\n",
      "(0.07132538797478023, 0.14690054107779724)\n",
      "saving...\n",
      "(0.06175500626441901, 0.1669341723951541)\n",
      "saving...\n",
      "(0.08212394710684234, 0.17095701625881132)\n",
      "saving...\n",
      "(0.06156650783085492, 0.16704794604779283)\n",
      "saving...\n",
      "(0.08676123552700218, 0.24618404342646183)\n",
      "saving...\n",
      "(0.0770606814691242, 0.15193435525467372)\n",
      "saving...\n",
      "(0.1050315079867182, 0.25577644356122636)\n",
      "saving...\n",
      "(0.08241698496734025, 0.21603937099735238)\n",
      "saving...\n",
      "(0.10696058399374435, 0.24366235408652076)\n",
      "saving...\n",
      "(0.0862067192885246, 0.2245804485964749)\n",
      "saving...\n",
      "(0.08263809783742053, 0.1917183228676716)\n",
      "saving...\n",
      "(0.08479776231128991, 0.2426079073318824)\n",
      "saving...\n",
      "(0.0679938847275908, 0.17579529302394356)\n",
      "saving...\n",
      "(0.056738154970480875, 0.1598676324581244)\n",
      "saving...\n",
      "(0.06509328495330383, 0.15171183787109674)\n",
      "saving...\n",
      "(0.137811354782941, 0.3718563674860015)\n",
      "saving...\n",
      "(0.09390266318533873, 0.22720289261558976)\n",
      "saving...\n",
      "(0.11861507739365469, 0.2690028307583004)\n",
      "saving...\n",
      "(0.0663991781437358, 0.17328153516504194)\n",
      "saving...\n",
      "(0.08383280964750076, 0.24534133733736588)\n",
      "saving...\n",
      "(0.06227654787987313, 0.2093732947554152)\n",
      "saving...\n",
      "(0.06135078797665797, 0.343493711903787)\n",
      "saving...\n",
      "(0.09737088869477746, 0.19946528351063653)\n",
      "saving...\n",
      "(0.05401911245994772, 0.22457560845612856)\n",
      "saving...\n",
      "(0.07056253413129984, 0.17142955591471784)\n",
      "saving...\n",
      "(0.062477706892868974, 0.3012353064847123)\n",
      "saving...\n",
      "(0.07546371086495442, 0.18645814043696912)\n",
      "saving...\n",
      "(0.08156832140909173, 0.20385180493448712)\n",
      "saving...\n",
      "(0.06735470111404487, 0.12332150444957116)\n",
      "saving...\n",
      "(0.08294973875579499, 0.18119267658456698)\n",
      "saving...\n",
      "(0.07476655011334792, 0.15211959281979812)\n",
      "saving...\n",
      "(0.09502305063985504, 0.2794755864923166)\n",
      "saving...\n",
      "(0.0758508753609821, 0.21806324719071712)\n",
      "saving...\n",
      "(0.07631506249719354, 0.16385936763191047)\n",
      "saving...\n",
      "(0.08508931562645207, 0.3482651455924382)\n",
      "saving...\n",
      "(0.08593942858931185, 0.2340728739569441)\n",
      "saving...\n",
      "(0.08485397527993788, 0.22661437416817162)\n",
      "saving...\n",
      "(0.052219181238643456, 0.11000201696940957)\n",
      "saving...\n",
      "(0.06951533729882814, 0.21966769211746967)\n",
      "saving...\n",
      "(0.11623698112291622, 0.2951180732883047)\n",
      "saving...\n",
      "(0.06979059710035994, 0.20501483768181294)\n",
      "saving...\n",
      "(0.08502565974787442, 0.2160849544517872)\n",
      "saving...\n",
      "(0.09297724899205366, 0.24850838479249224)\n",
      "saving...\n",
      "(0.07835495872309259, 0.198487494496902)\n",
      "saving...\n",
      "(0.07429450589223614, 0.13759571947956092)\n",
      "saving...\n",
      "(0.1029143439449501, 0.45718076884327813)\n",
      "saving...\n",
      "(0.06596104540051106, 0.23201311104565955)\n",
      "saving...\n",
      "(0.04888113083036942, 0.19449864693534574)\n",
      "saving...\n",
      "(0.07270973950692768, 0.24694951503964194)\n",
      "saving...\n",
      "(0.08917434213383668, 0.18087162744338287)\n",
      "saving...\n",
      "(0.07596159076074022, 0.35536173747378597)\n",
      "saving...\n",
      "(0.0795387761401184, 0.27315195072614734)\n",
      "saving...\n",
      "(0.06821029547417702, 0.22586904899588695)\n",
      "saving...\n",
      "(0.0524217765324725, 0.2161190012541439)\n",
      "saving...\n",
      "(0.06627716459083474, 0.12769152901716324)\n",
      "saving...\n",
      "(0.08594601074756798, 0.1826140687208652)\n",
      "saving...\n",
      "(0.07332813824760077, 0.2620329041986743)\n",
      "saving...\n",
      "(0.09394447998261461, 0.2822575215621923)\n",
      "saving...\n",
      "(0.08576977762515416, 0.23591830657553114)\n",
      "saving...\n",
      "(0.08666959039311012, 0.20869621858767548)\n",
      "saving...\n",
      "(0.0650556803554938, 0.21076855175439918)\n",
      "saving...\n",
      "(0.07572978880207303, 0.35117053716686464)\n",
      "saving...\n",
      "(0.07836862117344988, 0.19254434021882585)\n",
      "saving...\n",
      "(0.08154408503039569, 0.17931227838895958)\n",
      "saving...\n",
      "(0.06300613130369502, 0.1156049175841256)\n",
      "saving...\n",
      "(0.09110826427679337, 0.3418643075560615)\n",
      "saving...\n",
      "(0.1023241336516108, 0.2551835745557783)\n",
      "saving...\n",
      "(0.0670387228126569, 0.30951669860766823)\n",
      "saving...\n",
      "(0.0773739925536346, 0.19099729483985609)\n",
      "saving...\n",
      "(0.08111041208899919, 0.24861696199660124)\n",
      "saving...\n",
      "(0.06248185076447296, 0.13448634932811276)\n",
      "saving...\n",
      "(0.08690816031087055, 0.22774937013921223)\n",
      "saving...\n",
      "(0.10239267121010107, 0.2497814254706857)\n",
      "saving...\n",
      "(0.07913860783794299, 0.16434571943897294)\n",
      "saving...\n",
      "(0.08946086277928234, 0.23912881273913533)\n",
      "saving...\n",
      "(0.07963805554164385, 0.24027109119951212)\n",
      "saving...\n",
      "(0.08799514255850213, 0.19846061329398798)\n",
      "saving...\n",
      "(0.048474548218345, 0.1682870935412623)\n",
      "saving...\n",
      "(0.09274592107124442, 0.29745072294823294)\n",
      "saving...\n",
      "(0.09469360284665472, 0.21840914681858992)\n",
      "saving...\n",
      "(0.07119373906992613, 0.1766837397320849)\n",
      "saving...\n",
      "(0.08108786936972029, 0.17873488470472104)\n",
      "saving...\n",
      "(0.08884821254126174, 0.2519236297950981)\n",
      "saving...\n",
      "(0.08127673532256498, 0.2904358177393313)\n",
      "saving...\n",
      "(0.05356909655741401, 0.12793030114270618)\n",
      "saving...\n",
      "(0.09458540727530909, 0.18935813696434015)\n",
      "saving...\n",
      "(0.0713240293367971, 0.16309447854561526)\n",
      "saving...\n",
      "(0.07759535427284618, 0.1831241445265694)\n",
      "saving...\n",
      "(0.08071736879010759, 0.2093348306606078)\n",
      "saving...\n",
      "(0.06198108993893519, 0.12153286359603352)\n",
      "saving...\n",
      "(0.07511583433665156, 0.41852029634348276)\n",
      "saving...\n",
      "(0.06523775981066296, 0.2213370061765923)\n",
      "saving...\n",
      "(0.08148298831438171, 0.24084895608630177)\n",
      "saving...\n",
      "(0.055739487184717273, 0.12881305140603813)\n",
      "saving...\n",
      "(0.11806711765918809, 0.39131334367058596)\n",
      "saving...\n",
      "(0.08996638338841184, 0.18122495892680549)\n",
      "saving...\n",
      "(0.0946167550156707, 0.2965269492721146)\n",
      "saving...\n",
      "(0.05323760165352004, 0.13316103875221802)\n",
      "saving...\n",
      "(0.11767919445621723, 0.34116440986331653)\n",
      "saving...\n",
      "(0.0834326037490752, 0.17226304331576944)\n",
      "saving...\n",
      "(0.07410740671903354, 0.17462655361452836)\n",
      "saving...\n",
      "(0.05722679209087009, 0.1662648599680247)\n",
      "saving...\n",
      "(0.10113153905301187, 0.21165982345796108)\n",
      "saving...\n",
      "(0.10144142053104017, 0.41403922994126763)\n",
      "saving...\n",
      "(0.0849521421920446, 0.4150350202719352)\n",
      "saving...\n",
      "(0.08940873162149827, 0.18116322298321635)\n",
      "saving...\n",
      "(0.057523551165641874, 0.173261486378457)\n",
      "saving...\n",
      "(0.06976142973112928, 0.3089243105932713)\n",
      "saving...\n",
      "(0.09711800527683695, 0.27439503296060225)\n",
      "saving...\n",
      "(0.07374709063361738, 0.179670764268779)\n",
      "saving...\n",
      "(0.06952457385577632, 0.2580926253516249)\n",
      "saving...\n",
      "(0.0693176809010842, 0.37052326881875586)\n",
      "saving...\n",
      "(0.07644830379947593, 0.18929569143868383)\n",
      "saving...\n",
      "(0.10034740243285785, 0.21589937143062946)\n",
      "saving...\n",
      "(0.08771766704939252, 0.24446800050563636)\n",
      "saving...\n",
      "(0.09186823941502627, 0.23114781822031058)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "(0.054776694806338316, 0.09298858831734774)\n",
      "saving...\n",
      "(0.084066969670894, 0.19768696752931644)\n",
      "saving...\n",
      "(0.06955780545341655, 0.23923505810431472)\n",
      "saving...\n",
      "(0.06988611219174534, 0.4328012708751327)\n",
      "saving...\n",
      "(0.10178731450698691, 0.4247008409160271)\n",
      "saving...\n",
      "(0.056775324784037996, 0.15410295806751526)\n",
      "saving...\n",
      "(0.07786825862382458, 0.19403742870257618)\n",
      "saving...\n",
      "(0.07602393212293469, 0.1459767039584732)\n",
      "saving...\n",
      "(0.07512680500178318, 0.2635505844560569)\n",
      "saving...\n",
      "(0.0872747656996751, 0.20545616497796781)\n",
      "saving...\n",
      "(0.11608126902581725, 0.26875760630835566)\n",
      "saving...\n",
      "(0.10921258300492068, 0.24076867218558448)\n",
      "saving...\n",
      "(0.08283226041098785, 0.2096597285831406)\n",
      "saving...\n",
      "(0.0683422953501187, 0.29557499219728217)\n",
      "saving...\n",
      "(0.07905734161874323, 0.23368788051427378)\n",
      "saving...\n",
      "(0.06862659439755496, 0.13109273508711478)\n",
      "saving...\n",
      "(0.07927810794678178, 0.29427499096033893)\n",
      "saving...\n",
      "(0.07024703624454108, 0.15627173917431467)\n",
      "saving...\n",
      "(0.06668783626749042, 0.14201070877208988)\n",
      "saving...\n",
      "(0.09614068441892452, 0.18198209591848666)\n",
      "saving...\n",
      "(0.07030153453842171, 0.24424566516996332)\n",
      "saving...\n",
      "(0.06143390254148269, 0.21767066548653455)\n",
      "saving...\n",
      "(0.046263525270707456, 0.17833147399124438)\n",
      "saving...\n",
      "(0.07430296858073583, 0.17894918218897393)\n",
      "saving...\n",
      "(0.10184475836246454, 0.21635897191965414)\n",
      "saving...\n",
      "(0.0903603793949303, 0.23106154443412555)\n",
      "saving...\n",
      "(0.07884703962476008, 0.18711635850599867)\n",
      "saving...\n",
      "(0.07404074321523378, 0.14951803583163398)\n",
      "saving...\n",
      "(0.06816687303887815, 0.24684142927475225)\n",
      "saving...\n",
      "(0.10909882471467318, 0.25492051206304434)\n",
      "saving...\n",
      "(0.07416920503117938, 0.18299994794539307)\n",
      "saving...\n",
      "(0.0882370494057518, 0.19375781841568968)\n",
      "saving...\n",
      "(0.05833439441349234, 0.20048233516404573)\n",
      "saving...\n",
      "(0.09385018162881192, 0.25979160322327743)\n",
      "saving...\n",
      "(0.07174414991160409, 0.22088976049719486)\n",
      "saving...\n",
      "(0.05190203048449925, 0.2072563486208018)\n",
      "saving...\n",
      "(0.09718447805375373, 0.28537917670942037)\n",
      "saving...\n",
      "(0.08219137340116187, 0.1744373075207632)\n",
      "saving...\n",
      "(0.08302836574322145, 0.2140554942971221)\n",
      "saving...\n",
      "(0.07129664845394118, 0.17583434434262019)\n",
      "saving...\n",
      "(0.080269278252219, 0.28901428225301956)\n",
      "saving...\n",
      "(0.10546382413668229, 0.44409868870857955)\n",
      "saving...\n",
      "(0.08976417540124014, 0.24084492767129256)\n",
      "saving...\n",
      "(0.07683913170959979, 0.2249732772651575)\n",
      "saving...\n",
      "(0.06929341859476214, 0.15916496174617478)\n",
      "saving...\n",
      "(0.061355134179119065, 0.15308157527963004)\n",
      "saving...\n",
      "(0.07054176544964307, 0.17679557909821095)\n",
      "saving...\n",
      "(0.06981134060334131, 0.16955457712489774)\n",
      "saving...\n",
      "(0.0770790968204023, 0.23782852499864576)\n",
      "saving...\n",
      "(0.09249287842924461, 0.4742172146817668)\n",
      "saving...\n",
      "(0.09374168891000349, 0.26000056189305676)\n",
      "saving...\n",
      "(0.07468054459347032, 0.2601201894766381)\n",
      "saving...\n",
      "(0.06855522938623987, 0.16043829886545763)\n",
      "saving...\n",
      "(0.07288082850704174, 0.21938425146031695)\n",
      "saving...\n",
      "(0.08654176306729121, 0.21248448421841046)\n",
      "saving...\n",
      "(0.05649291606800259, 0.22569296405191974)\n",
      "saving...\n",
      "(0.10533350905235998, 0.2772911821822011)\n",
      "saving...\n",
      "(0.09850774622221439, 0.2320915141313067)\n",
      "saving...\n",
      "(0.10003573606228142, 0.2942813624540151)\n",
      "saving...\n",
      "(0.08494267944057986, 0.22338366606022678)\n",
      "saving...\n",
      "(0.07785754586038882, 0.24182748928138287)\n",
      "saving...\n",
      "(0.10500158177665735, 0.2583009461805308)\n",
      "saving...\n",
      "(0.07056290533419583, 0.1814137132316372)\n",
      "saving...\n",
      "(0.09106579076946114, 0.2198674480382101)\n",
      "saving...\n",
      "(0.06392499336682221, 0.1467286528582132)\n",
      "saving...\n",
      "(0.08225901970787795, 0.3387595202020882)\n",
      "saving...\n",
      "(0.05949532173272152, 0.14714585264220226)\n",
      "saving...\n",
      "(0.07436704652459057, 0.17889179447798875)\n",
      "saving...\n",
      "(0.08835618090088794, 0.416045542886113)\n",
      "saving...\n",
      "(0.10728648570623023, 0.4152397496982261)\n",
      "saving...\n",
      "(0.06997440819172433, 0.25930499094831605)\n",
      "saving...\n",
      "(0.13351304823126522, 0.3774143117580655)\n",
      "saving...\n",
      "(0.12486980786789993, 0.3483904875797526)\n",
      "saving...\n",
      "(0.10244557589507051, 0.4144476394049763)\n",
      "saving...\n",
      "(0.07798853554735273, 0.2134618914707846)\n",
      "saving...\n",
      "(0.09725222238437531, 0.2875084941047486)\n",
      "saving...\n",
      "(0.08631055034621338, 0.18235648336974364)\n",
      "saving...\n",
      "(0.09007263543304023, 0.29004271996456416)\n",
      "saving...\n",
      "(0.07032751798214479, 0.3002155361534022)\n",
      "saving...\n",
      "(0.08329542618500244, 0.5639032565482824)\n",
      "saving...\n",
      "(0.09047327451508186, 0.20757826301150537)\n",
      "saving...\n",
      "(0.06389804409301468, 0.35882494916205643)\n",
      "saving...\n",
      "(0.09749971836784672, 0.22581656804927572)\n",
      "saving...\n",
      "(0.060856008387792496, 0.17627130559818147)\n",
      "saving...\n",
      "(0.14377697278540771, 0.36681065569226967)\n",
      "saving...\n",
      "(0.07189743543436357, 0.19272057119111705)\n",
      "saving...\n",
      "(0.08281161179772166, 0.15977412812742695)\n",
      "saving...\n",
      "(0.06880478315291079, 0.3068767556069027)\n",
      "saving...\n",
      "(0.06817078762043893, 0.22220461572827385)\n",
      "saving...\n",
      "(0.07383853917649671, 0.25748808631583703)\n",
      "saving...\n",
      "(0.09261137286510315, 0.25517958222522363)\n",
      "saving...\n",
      "(0.06637159001090387, 0.2790141009524817)\n",
      "saving...\n",
      "(0.09116101357789913, 0.18052777871995254)\n",
      "saving...\n",
      "(0.07501371534680404, 0.18310868099527494)\n",
      "saving...\n",
      "(0.06666525606879677, 0.16770827120101384)\n",
      "saving...\n",
      "(0.054551161549485416, 0.1976982702758422)\n",
      "saving...\n",
      "(0.07777887595005084, 0.15785600826020804)\n",
      "saving...\n",
      "(0.06624717915231537, 0.15910785421182014)\n",
      "saving...\n",
      "(0.08265752130415872, 0.20172470714796142)\n",
      "saving...\n",
      "(0.0780422503751189, 0.2016542240945824)\n",
      "saving...\n",
      "(0.05233669439344673, 0.13635386624891482)\n",
      "saving...\n",
      "(0.06932283296831586, 0.20827403324067686)\n",
      "saving...\n",
      "(0.08655688042821892, 0.1920982865154837)\n",
      "saving...\n",
      "(0.1114641691666996, 0.3282023809442006)\n",
      "saving...\n",
      "(0.07854052546928972, 0.2343035731881311)\n",
      "saving...\n",
      "(0.08865969912545335, 0.18602648463160928)\n",
      "saving...\n",
      "(0.08622815321849878, 0.19635442678327744)\n",
      "saving...\n",
      "(0.08976960599977034, 0.3004259799218229)\n",
      "saving...\n",
      "(0.11366910551220617, 0.24854413129606873)\n",
      "saving...\n",
      "(0.10112627551996652, 0.28268354929035694)\n",
      "saving...\n",
      "(0.10813106887852893, 0.18657299967923296)\n",
      "saving...\n",
      "(0.0872964602571099, 0.21623460607524037)\n",
      "saving...\n",
      "(0.06668570235022603, 0.2790503364755199)\n",
      "saving...\n",
      "(0.053217305478621316, 0.18035076774346298)\n",
      "saving...\n",
      "(0.10837018412325511, 0.2559109995381415)\n",
      "saving...\n",
      "(0.0953756040747907, 0.20968741894898943)\n",
      "saving...\n",
      "(0.05997336894873711, 0.20502949220428612)\n",
      "saving...\n",
      "(0.09988946316439615, 0.20900567506812665)\n",
      "saving...\n",
      "(0.13645779161418206, 0.3681314509995794)\n",
      "saving...\n",
      "(0.06464773659173174, 0.2716210261106102)\n",
      "saving...\n",
      "(0.0583389348532983, 0.13337403552954144)\n",
      "saving...\n",
      "(0.07963813463397088, 0.23662629747167585)\n",
      "saving...\n",
      "(0.06863365808779938, 0.15143237629156883)\n",
      "saving...\n",
      "(0.05749271956219829, 0.1526450788636142)\n",
      "saving...\n",
      "(0.08663965970033086, 0.22160044080951766)\n",
      "saving...\n",
      "(0.05907659060164808, 0.22927677234148888)\n",
      "saving...\n",
      "(0.0927149117603755, 0.2517553218099992)\n",
      "saving...\n",
      "(0.06748003265685908, 0.16140245889694138)\n",
      "saving...\n",
      "(0.07620346906107493, 0.1612570228992221)\n",
      "saving...\n",
      "(0.10562315115091805, 0.2142368602840096)\n",
      "saving...\n",
      "(0.10905842065671142, 0.32050507059404754)\n",
      "saving...\n",
      "(0.10740186497757188, 0.2685744503977846)\n",
      "saving...\n",
      "(0.06210191116193986, 0.16917470619594213)\n",
      "saving...\n",
      "(0.0687288452181051, 0.21261386351167888)\n",
      "saving...\n",
      "(0.10337060654332529, 0.29565173151912394)\n",
      "saving...\n",
      "(0.0934242245702869, 0.22215987913821467)\n",
      "saving...\n",
      "(0.059860471382264406, 0.2684564241063964)\n",
      "saving...\n",
      "(0.08488638805276716, 0.21756621085751404)\n",
      "saving...\n",
      "(0.07598482319953559, 0.18548946646188894)\n",
      "saving...\n",
      "(0.0850320896798857, 0.37543982823350486)\n",
      "saving...\n",
      "(0.07589499334964615, 0.3662096963771457)\n",
      "saving...\n",
      "(0.06429839622339366, 0.17636569281530975)\n",
      "saving...\n",
      "(0.06536252808068868, 0.2778341795675389)\n",
      "saving...\n",
      "(0.09686763407511238, 0.2383171822738824)\n",
      "saving...\n",
      "(0.0990826568574888, 0.31258747145724536)\n",
      "saving...\n",
      "(0.06886593641209483, 0.16998362807212203)\n",
      "saving...\n",
      "(0.07820358119229458, 0.18967305232610432)\n",
      "saving...\n",
      "(0.1518470695162445, 0.3220183088677256)\n",
      "saving...\n",
      "(0.09249550719745218, 0.15896704695839753)\n",
      "saving...\n",
      "(0.08316162810825836, 0.23637181350653383)\n",
      "saving...\n",
      "(0.0828583897973594, 0.1815790584459944)\n",
      "saving...\n",
      "(0.0758420474892415, 0.13571734998112983)\n",
      "saving...\n",
      "(0.08869807173021092, 0.23421069757371063)\n",
      "saving...\n",
      "(0.08696541069125586, 0.18878763834176035)\n",
      "saving...\n",
      "(0.07626319686190326, 0.18260622427885306)\n",
      "saving...\n",
      "(0.08420387944909129, 0.4823402723104394)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "(0.07397976692010143, 0.163020023276397)\n",
      "saving...\n",
      "(0.07093125810724622, 0.36088688008877284)\n",
      "saving...\n",
      "(0.1373207688575817, 0.3150473483818157)\n",
      "saving...\n",
      "(0.10104248171727807, 0.3844060401261116)\n",
      "saving...\n",
      "(0.06298894104050427, 0.13773676653009387)\n",
      "saving...\n",
      "(0.07566203611673306, 0.41597026839462203)\n",
      "saving...\n",
      "(0.06956643589385723, 0.15604425855107235)\n",
      "saving...\n",
      "(0.07060009962103903, 0.2712273410392617)\n",
      "saving...\n",
      "(0.08090167408765994, 0.21571381100650486)\n",
      "saving...\n",
      "(0.09502619406941604, 0.2629196140490642)\n",
      "saving...\n",
      "(0.0889257905393459, 0.23021111371897887)\n",
      "saving...\n",
      "(0.13424562412243077, 0.30634776951770265)\n",
      "saving...\n",
      "(0.06959700337964049, 0.14998980416233493)\n",
      "saving...\n",
      "(0.0701008968444914, 0.22223822375941632)\n",
      "saving...\n",
      "(0.0862904008317897, 0.23327422810282472)\n",
      "saving...\n",
      "(0.12220254888684115, 0.33556024695236203)\n",
      "saving...\n",
      "(0.09474002474787087, 0.2447208176614184)\n",
      "saving...\n",
      "(0.08172389669352517, 0.1796107108221837)\n",
      "saving...\n",
      "(0.11481993751251493, 0.25975717343580224)\n",
      "saving...\n",
      "(0.1065190945871033, 0.2629469604075768)\n",
      "saving...\n",
      "(0.10313408248991768, 0.2635052062760891)\n",
      "saving...\n",
      "(0.06148324546375826, 0.1289716866779739)\n",
      "saving...\n",
      "(0.08662040317733545, 0.16584355359580993)\n",
      "saving...\n",
      "(0.07161040353426794, 0.15585119398246186)\n",
      "saving...\n",
      "(0.08452875316755402, 0.15570666824057894)\n",
      "saving...\n",
      "(0.09019391495171472, 0.1984623399289371)\n",
      "saving...\n",
      "(0.07204134285557207, 0.19107207456858974)\n",
      "saving...\n",
      "(0.09732786059194969, 0.27577643544121594)\n",
      "saving...\n",
      "(0.09225247728520719, 0.4683851134393203)\n",
      "saving...\n",
      "(0.06503005320378803, 0.1766764405473605)\n",
      "saving...\n",
      "(0.08960778359815975, 0.2080396751477651)\n",
      "saving...\n",
      "(0.08312276085144761, 0.19863873480217942)\n",
      "saving...\n",
      "(0.082484933501092, 0.3891452804608098)\n",
      "saving...\n",
      "(0.07090312140733995, 0.16978840699829495)\n",
      "saving...\n",
      "(0.09449450056386531, 0.23053207825839334)\n",
      "saving...\n",
      "(0.0839658965745148, 0.36126442045931706)\n",
      "saving...\n",
      "(0.07961157219524717, 0.18553827709310816)\n",
      "saving...\n",
      "(0.08288281973116149, 0.17146173397779474)\n",
      "saving...\n",
      "(0.11221562052780819, 0.3656013979215058)\n",
      "saving...\n",
      "(0.09055867541284271, 0.3514474275535583)\n",
      "saving...\n",
      "(0.07166929263209601, 0.15376717269844717)\n",
      "saving...\n",
      "(0.13179919400055007, 0.3062942452278364)\n",
      "saving...\n",
      "(0.09435627411996912, 0.1734894307295766)\n",
      "saving...\n",
      "(0.09774451372290306, 0.2130411457823689)\n",
      "saving...\n",
      "(0.07031522246712828, 0.21786464710549264)\n",
      "saving...\n",
      "(0.06563155057969937, 0.15645843998140996)\n",
      "saving...\n",
      "(0.10956774663357438, 0.246481085271697)\n",
      "saving...\n",
      "(0.0885522980531043, 0.27100688995016853)\n",
      "saving...\n",
      "(0.0859475479553054, 0.1946489998182357)\n",
      "saving...\n",
      "(0.07379539220855741, 0.2822282304135775)\n",
      "saving...\n",
      "(0.08155059175703958, 0.2260397583350628)\n",
      "saving...\n",
      "(0.06999472389982618, 0.13392264292851447)\n",
      "saving...\n",
      "(0.08939310712699418, 0.28868012350898514)\n",
      "saving...\n",
      "(0.07979069289644287, 0.2650939493176493)\n",
      "saving...\n",
      "(0.05985122034860879, 0.17906045701802845)\n",
      "saving...\n",
      "(0.09576984402070829, 0.24830250495010006)\n",
      "saving...\n",
      "(0.09610392985497586, 0.41590251815828405)\n",
      "saving...\n",
      "(0.12191327487444448, 0.3218000572095066)\n",
      "saving...\n",
      "(0.0793396921406862, 0.2302663922488838)\n",
      "saving...\n",
      "(0.11842787296232928, 0.3025847720460324)\n",
      "saving...\n",
      "(0.08513270306129796, 0.25145967026748683)\n",
      "saving...\n",
      "(0.07083672179531006, 0.1446499338524886)\n",
      "saving...\n",
      "(0.06643351999154612, 0.20711095161429582)\n",
      "saving...\n",
      "(0.07671942909541697, 0.23092600412359177)\n",
      "saving...\n",
      "(0.12045348486074714, 0.25957189665879027)\n",
      "saving...\n",
      "(0.10627001960332494, 0.3448630691202458)\n",
      "saving...\n",
      "(0.07391953056966424, 0.2846984576787865)\n",
      "saving...\n",
      "(0.06556359744043984, 0.17455266883905315)\n",
      "saving...\n",
      "(0.07120181512372313, 0.13058055612199868)\n",
      "saving...\n",
      "(0.0814757042943018, 0.23471012161652854)\n",
      "saving...\n",
      "(0.0929145507616994, 0.1790457632893821)\n",
      "saving...\n",
      "(0.07915572445560315, 0.20130183217315692)\n",
      "saving...\n",
      "(0.08601466316588362, 0.2724264777810684)\n",
      "saving...\n",
      "(0.10653638256384348, 0.22016990314025994)\n",
      "saving...\n",
      "(0.09229859452285319, 0.21814690080671256)\n",
      "saving...\n",
      "(0.08981161792326993, 0.27709501817393273)\n",
      "saving...\n",
      "(0.08689136550515544, 0.2311695407428748)\n",
      "saving...\n",
      "(0.060264890476241756, 0.12420918759645404)\n",
      "saving...\n",
      "(0.10853486108173356, 0.2993387650615344)\n",
      "saving...\n",
      "(0.10015064585537896, 0.34675197419984055)\n",
      "saving...\n",
      "(0.1060855596416109, 0.24505381197293563)\n",
      "saving...\n",
      "(0.06295478694712124, 0.13678743203425953)\n",
      "saving...\n",
      "(0.08722573226477033, 0.1787821895611845)\n",
      "saving...\n",
      "(0.10699397615164223, 0.24658043624316198)\n",
      "saving...\n",
      "(0.07208197733220607, 0.2573918619575544)\n",
      "saving...\n",
      "(0.08427312814633882, 0.2995251449808699)\n",
      "saving...\n",
      "(0.08656807246690058, 0.17258311599212017)\n",
      "saving...\n",
      "(0.07074644097737118, 0.19411952920313238)\n",
      "saving...\n",
      "(0.09799752239904248, 0.26030971117632146)\n",
      "saving...\n",
      "(0.07044445598567617, 0.13362860106363034)\n",
      "saving...\n",
      "(0.1268001586885088, 0.31947768047321623)\n",
      "saving...\n",
      "(0.07628478172177912, 0.2662587867285901)\n",
      "saving...\n",
      "(0.06783741806767243, 0.14166203798463975)\n",
      "saving...\n",
      "(0.07839889546820526, 0.362758245343942)\n",
      "saving...\n",
      "(0.08826538633262063, 0.20575716029200988)\n",
      "saving...\n",
      "(0.07245366123340048, 0.19869212640927483)\n",
      "saving...\n",
      "(0.08126957621369972, 0.21096274164203632)\n",
      "saving...\n",
      "(0.11039516291015923, 0.20686427840856952)\n",
      "saving...\n",
      "(0.11617620698454749, 0.24268027147491236)\n",
      "saving...\n",
      "(0.08461328311089965, 0.1943006295505253)\n",
      "saving...\n",
      "(0.06476779829055809, 0.2193791088843305)\n",
      "saving...\n",
      "(0.08468193175178847, 0.19383366925132117)\n",
      "saving...\n",
      "(0.08124179481269857, 0.23983453078883327)\n",
      "saving...\n",
      "(0.06565342320039017, 0.28259298908097963)\n",
      "saving...\n",
      "(0.10964269285705344, 0.22011525780218755)\n",
      "saving...\n",
      "(0.07410963709762824, 0.18282300430135018)\n",
      "saving...\n",
      "(0.10934472759857465, 0.33669048783028976)\n",
      "saving...\n",
      "(0.09077923468421763, 0.3169942430099609)\n",
      "saving...\n",
      "(0.07352800924032543, 0.21814049388122486)\n",
      "saving...\n",
      "(0.10205871231914544, 0.35478136587272924)\n",
      "saving...\n",
      "(0.08103308736351686, 0.22631134223037017)\n",
      "saving...\n",
      "(0.06377434870263134, 0.13211466525249516)\n",
      "saving...\n",
      "(0.08232987351683117, 0.1425495508027784)\n",
      "saving...\n",
      "(0.06384433521567923, 0.17465982448127776)\n",
      "saving...\n",
      "(0.07789582037322072, 0.23960866725823476)\n",
      "saving...\n",
      "(0.07316653723650177, 0.1639405432146768)\n",
      "saving...\n",
      "(0.06210987960768094, 0.15352969001623254)\n",
      "saving...\n",
      "(0.083544657757319, 0.2036184949800016)\n",
      "saving...\n",
      "(0.08305931326961769, 0.37233037096485055)\n",
      "saving...\n",
      "(0.08027407796345239, 0.17097844438843068)\n",
      "saving...\n",
      "(0.07267555081207391, 0.3280684162480258)\n",
      "saving...\n",
      "(0.09957168461097468, 0.4928529303781556)\n",
      "saving...\n",
      "(0.10279699332033436, 0.2957204875031049)\n",
      "saving...\n",
      "(0.07962576050953787, 0.13868103188600042)\n",
      "saving...\n",
      "(0.09934135330242627, 0.2584890200919978)\n",
      "saving...\n",
      "(0.08166953199500354, 0.1781245920352173)\n",
      "saving...\n",
      "(0.09677794758994639, 0.23137809352257982)\n",
      "saving...\n",
      "(0.07445815722368505, 0.16541108909935953)\n",
      "saving...\n",
      "(0.0910925536992934, 0.2283914232965775)\n",
      "saving...\n",
      "(0.07907511443268798, 0.2791855321879806)\n",
      "saving...\n",
      "(0.06272498421940247, 0.14724498296513713)\n",
      "saving...\n",
      "(0.08555712692027598, 0.17735515621333348)\n",
      "saving...\n",
      "(0.09585963224925556, 0.179802002746961)\n",
      "saving...\n",
      "(0.07658617475817525, 0.2659429680560281)\n",
      "saving...\n",
      "(0.09038348585569235, 0.3584387408040634)\n",
      "saving...\n",
      "(0.08196610465540419, 0.21659202742864342)\n",
      "saving...\n",
      "(0.09849132622952213, 0.3533581797774658)\n",
      "saving...\n",
      "(0.10004732234716346, 0.33613473403342814)\n",
      "saving...\n",
      "(0.14851255304400268, 0.3179605582129097)\n",
      "saving...\n",
      "(0.07535820053604056, 0.16981737859750273)\n",
      "saving...\n",
      "(0.06570105993387627, 0.12479372904920796)\n",
      "saving...\n",
      "(0.061060856817491786, 0.2689744633507312)\n",
      "saving...\n",
      "(0.1497584321607294, 0.39483022518185873)\n",
      "saving...\n",
      "(0.0683440993061887, 0.3056012162883248)\n",
      "saving...\n",
      "(0.0770035473306036, 0.2413821344684393)\n",
      "saving...\n",
      "(0.08554102792533337, 0.19084541626225623)\n",
      "saving...\n",
      "(0.09446176405843941, 0.2738727944262601)\n",
      "saving...\n",
      "(0.0685484085311277, 0.1813496974491006)\n",
      "saving...\n",
      "(0.06373426530106421, 0.22263186765048587)\n",
      "saving...\n",
      "(0.06780045331104696, 0.34137979738292124)\n",
      "saving...\n",
      "(0.06812496879360219, 0.2374396001276552)\n",
      "saving...\n",
      "(0.05566079360511816, 0.21490273322454562)\n",
      "saving...\n",
      "(0.07324587693940056, 0.2331474052659899)\n",
      "saving...\n",
      "(0.09068946859637754, 0.2500764819805993)\n",
      "saving...\n",
      "(0.0947673035221638, 0.20449730794758839)\n",
      "saving...\n",
      "(0.0904715612632153, 0.20217505717025727)\n",
      "saving...\n",
      "(0.07650985950704324, 0.1513808834125836)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "(0.08967035482994681, 0.22160806259525298)\n",
      "saving...\n",
      "(0.056000927568984685, 0.2584861473671135)\n",
      "saving...\n",
      "(0.1035096103466351, 0.2633790288697467)\n",
      "saving...\n",
      "(0.0798165244182026, 0.16555770538798747)\n",
      "saving...\n",
      "(0.12296851166808306, 0.27444374776585145)\n",
      "saving...\n",
      "(0.10874337749984729, 0.22343811430809862)\n",
      "saving...\n",
      "(0.0907702210271072, 0.27741022860868453)\n",
      "saving...\n",
      "(0.08547574673669892, 0.22255218167209115)\n",
      "saving...\n",
      "(0.054556565105560374, 0.16999029870554977)\n",
      "saving...\n",
      "(0.085022177130965, 0.3748168465907071)\n",
      "saving...\n",
      "(0.06684560823997077, 0.19283598769235527)\n",
      "saving...\n",
      "(0.0793552969368343, 0.19844631239805682)\n",
      "saving...\n",
      "(0.07283120658229318, 0.16682817175286616)\n",
      "saving...\n",
      "(0.07200513074345005, 0.2066077801473885)\n",
      "saving...\n",
      "(0.09724945690097864, 0.24992455677119343)\n",
      "saving...\n",
      "(0.0817921602233286, 0.2544376005608513)\n",
      "saving...\n",
      "(0.08711673676907757, 0.4319684367740514)\n",
      "saving...\n",
      "(0.07859719473166553, 0.13153312379262877)\n",
      "saving...\n",
      "(0.08664436708117697, 0.3647838762759968)\n",
      "saving...\n",
      "(0.0940055740679491, 0.22385472928481084)\n",
      "saving...\n",
      "(0.07043380020273968, 0.31754070286409175)\n",
      "saving...\n",
      "(0.10900752576628099, 0.39055439351414406)\n",
      "saving...\n",
      "(0.07316893245858384, 0.21734778270067545)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9c43efda10ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# from (64,168) to (64,191)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#=========== make the prediction ==============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mpred_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maux_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m#========== get prediction for next sequence ==================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mrewritten_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_window_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/wusai/wspy2/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/wusai/wspy2/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/wusai/wspy2/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/wusai/wspy2/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(n_epoches):\n",
    "    print('epoch: ',e+1, '/', n_epoches)\n",
    "    model.fit([train_aux_input,train_main_input], [train_y] , epochs=1, batch_size=32,verbose=1, shuffle=True)\n",
    "    model.save_weights(str(e)+'th_Epoch_weights.h5')\n",
    "    for i in range(n_batch):\n",
    "        batch_range = range(i*batch_size, (i+1)*batch_size)\n",
    "        for j in range(output_window_length): # j = [0.23], input_window_length+j = [168,191]\n",
    "            #=========== index, input, dimension check ====================\n",
    "            #print('\\n========= now predicting the index (start from 0): ',input_window_length+j, '=========')\n",
    "            #print('which means that the current input is: [0,' + str(input_window_length+j-1) + ']')\n",
    "            #print('aka. \":'+str(input_window_length+j)+'\"')\n",
    "            main_input = rewritten_input[batch_range,:input_window_length + j,0:4]\n",
    "            #print('so the main input for this round of prediction is:\\n', main_input)\n",
    "            #print('shape of the main input for this round of prediction is: ', main_input.shape) \n",
    "            # from (64,168,4) to (64,191,4)\n",
    "            aux_input = test_aux_input[batch_range,:input_window_length + j]\n",
    "            #print('shape of the auxiliary input for this round of prediction is: ', aux_input.shape) \n",
    "            # from (64,168) to (64,191)\n",
    "            #=========== make the prediction ==============================\n",
    "            pred_result = model.predict_on_batch([aux_input, main_input])\n",
    "            #========== get prediction for next sequence ==================\n",
    "            rewritten_input[batch_range, input_window_length + j, 0] = pred_result[:, -1 ,0]\n",
    "            #========== draw the prediction ===============================\n",
    "        \n",
    "        nd[i] = nd_metrics(test_main_input[batch_range, input_window_length:, 0], rewritten_input[batch_range, input_window_length:, 0], test_vi[batch_range])\n",
    "        rmse[i] = rmse_metrics(test_main_input[batch_range, input_window_length:, 0], rewritten_input[batch_range, input_window_length:, 0], test_vi[batch_range])\n",
    "        if (nd[i] <= 0.09 or rmse[i] <= 0.4 or (nd[i]<0.11 and rmse[i]<0.5)):\n",
    "            plot(test_main_input[i*batch_size:i*batch_size+8,:,0], rewritten_input[i*batch_size:i*batch_size+8,:,0], test_vi[i*batch_size:i*batch_size+8],8,i,e)\n",
    "            print(nd[i], rmse[i])\n",
    "    print('nd average: ', np.mean(nd))\n",
    "    print('rmse average: ', np.mean(rmse))\n",
    "    \n",
    "    print('nd min: ', np.min(nd))\n",
    "    print('rmse min: ', np.min(rmse))\n",
    "    \n",
    "    print('nd max: ', np.max(nd))\n",
    "    print('rmse max: ', np.max(rmse))\n",
    "    \n",
    "    np.save(str(e)+'thEpochOfND.npy', nd)\n",
    "    np.save(str(e)+'thEpochOfRMSE.npy', rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
